{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/\n",
      "\n",
      "0 directories, 0 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">import </span></span><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">sys.process._</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">res1_1</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;&quot;</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">res1_2</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;&quot;</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result3</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36msys.process._\u001b[39m\n",
       "\u001b[36mres1_1\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\u001b[39m\n",
       "\u001b[36mres1_2\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\u001b[39m\n",
       "\u001b[36mresult3\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys.process._\n",
    "\"rm -rf /tmp/hudi/\".!!\n",
    "\"mkdir -p /tmp/hudi\".!!\n",
    "lazy val result3 = \"tree -a /tmp/hudi/\".!!\n",
    "println(result3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/02 22:42:52 WARN Utils: Your hostname, DESKTOP-M94RUSC resolves to a loopback address: 127.0.1.1; using 172.17.75.227 instead (on interface eth0)\n",
      "25/03/02 22:42:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/03/02 22:42:53 INFO SparkContext: Running Spark version 3.3.2\n",
      "25/03/02 22:42:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/02 22:42:53 INFO ResourceUtils: ==============================================================\n",
      "25/03/02 22:42:53 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/03/02 22:42:53 INFO ResourceUtils: ==============================================================\n",
      "25/03/02 22:42:53 INFO SparkContext: Submitted application: HudiLocalSession\n",
      "25/03/02 22:42:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/03/02 22:42:53 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/03/02 22:42:53 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/03/02 22:42:53 INFO SecurityManager: Changing view acls to: ryan\n",
      "25/03/02 22:42:53 INFO SecurityManager: Changing modify acls to: ryan\n",
      "25/03/02 22:42:53 INFO SecurityManager: Changing view acls groups to: \n",
      "25/03/02 22:42:53 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/03/02 22:42:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ryan); groups with view permissions: Set(); users  with modify permissions: Set(ryan); groups with modify permissions: Set()\n",
      "25/03/02 22:42:53 INFO Utils: Successfully started service 'sparkDriver' on port 33883.\n",
      "25/03/02 22:42:53 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/03/02 22:42:53 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/03/02 22:42:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/03/02 22:42:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/03/02 22:42:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/03/02 22:42:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b00f8438-546f-4a63-b1ee-f15262e2ad9f\n",
      "25/03/02 22:42:53 INFO MemoryStore: MemoryStore started with capacity 4.4 GiB\n",
      "25/03/02 22:42:53 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/03/02 22:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/02 22:42:53 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "25/03/02 22:42:53 INFO Executor: Starting executor ID driver on host 172.17.75.227\n",
      "25/03/02 22:42:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/03/02 22:42:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38973.\n",
      "25/03/02 22:42:53 INFO NettyBlockTransferService: Server created on 172.17.75.227:38973\n",
      "25/03/02 22:42:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/03/02 22:42:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.17.75.227, 38973, None)\n",
      "25/03/02 22:42:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.75.227:38973 with 4.4 GiB RAM, BlockManagerId(driver, 172.17.75.227, 38973, None)\n",
      "25/03/02 22:42:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.75.227, 38973, None)\n",
      "25/03/02 22:42:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.17.75.227, 38973, None)\n",
      "Spark with Hudi is ready!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$cp.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.QuickstartUtils._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.hive.HiveExternalCatalog\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.JavaConversions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SaveMode._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.DataSourceReadOptions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.DataSourceWriteOptions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.common.table.HoodieTableConfig._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.config.HoodieWriteConfig._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.keygen.constant.KeyGeneratorOptions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.hudi.common.model.HoodieRecord\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.payloads.CustomMergeIntoConnector\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@39de1095"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.hudi:hudi-spark3.3-bundle_2.12:1.0.0`\n",
    "// import $ivy.`org.apache.hudi:hudi-common:1.0.0`\n",
    "import $ivy.`org.apache.spark:spark-sql_2.12:3.3.2`\n",
    "import $ivy.`org.apache.spark:spark-hive_2.12:3.3.2`\n",
    "import $cp.`CustomMergeIntoConnector.jar`\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.hudi.QuickstartUtils._\n",
    "import org.apache.spark.sql.hive.HiveExternalCatalog\n",
    "import scala.collection.JavaConversions._\n",
    "import org.apache.spark.sql.SaveMode._\n",
    "import org.apache.hudi.DataSourceReadOptions._\n",
    "import org.apache.hudi.DataSourceWriteOptions._\n",
    "import org.apache.hudi.common.table.HoodieTableConfig._\n",
    "import org.apache.hudi.config.HoodieWriteConfig._\n",
    "import org.apache.hudi.keygen.constant.KeyGeneratorOptions._\n",
    "import org.apache.hudi.common.model.HoodieRecord\n",
    "import com.payloads.CustomMergeIntoConnector\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"HudiLocalSession\")\n",
    "  .master(\"local[*]\")  // Runs on local machine\n",
    "  .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "  .config(\"spark.kryo.registrator\", \"org.apache.spark.HoodieKryoRegistrar\")\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\")\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\")\n",
    "  .config(\"spark.kryo.registrator\", \"org.apache.spark.HoodieSparkKryoRegistrar\")\n",
    "  .config(\"spark.driver.extraJavaOptions\", \"-Dscala.repl.maxprintstring=0\")\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "  \n",
    "// http://localhost:4040/jobs/\n",
    "println(\"Spark with Hudi is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/\n",
      "\n",
      "0 directories, 0 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val result = \"tree -a /tmp/hudi/\".!!\n",
    "println(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Insert Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# WARNING: Unable to get Instrumentation. Dynamic Attach failed. You may add this JAR as -javaagent manually, or supply -Djdk.attach.allowAttachSelf\n",
      "# WARNING: Unable to attach Serviceability Agent. Unable to attach even with module exceptions: [org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">columns</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Seq</span></span>[<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">List</span></span>(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;ts&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;uuid&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;fare&quot;</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;city&quot;</span></span>)\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">data</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Seq</span></span>[(<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Long</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Double</span></span>, <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>)] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">List</span></span>(\n",
       "  (\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1695159649087L</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;334e26e9-8355-45cc-97c6-c31daf0df330&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider-A&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver-K&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">19.1</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;san_francisco&quot;</span></span>\n",
       "  ),\n",
       "  (\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1695091554788L</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;e96c4396-3fad-413a-a942-4cb36106d721&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider-C&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver-M&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">27.7</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;san_francisco&quot;</span></span>\n",
       "  ),\n",
       "  (\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1695046462179L</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;9909a8b1-2d15-4d3d-8ec9-efc48c536a00&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider-D&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver-L&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">33.9</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;san_francisco&quot;</span></span>\n",
       "  ),\n",
       "  (\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1695516137016L</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;e3cf430c-889d-4015-bc98-59bdce1e530c&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider-F&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver-P&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">34.15</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;sao_paulo&quot;</span></span>\n",
       "  ),\n",
       "  (\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">1695115999911L</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;c8abbe79-8d89-47ea-b4ce-4d224bae5bfa&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;rider-J&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;driver-T&quot;</span></span>,\n",
       "    <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">17.85</span></span>,\n",
       "...\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">tableName</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;trips_table&quot;</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">basePath</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;file:///tmp/hudi/trips_table&quot;</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">inserts</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">DataFrame</span></span> = [ts: bigint, uuid: string ... 4 more fields]</code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mcolumns\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"ts\"\u001b[39m, \u001b[32m\"uuid\"\u001b[39m, \u001b[32m\"rider\"\u001b[39m, \u001b[32m\"driver\"\u001b[39m, \u001b[32m\"fare\"\u001b[39m, \u001b[32m\"city\"\u001b[39m)\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mSeq\u001b[39m[(\u001b[32mLong\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mDouble\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mList\u001b[39m(\n",
       "  (\n",
       "    \u001b[32m1695159649087L\u001b[39m,\n",
       "    \u001b[32m\"334e26e9-8355-45cc-97c6-c31daf0df330\"\u001b[39m,\n",
       "    \u001b[32m\"rider-A\"\u001b[39m,\n",
       "    \u001b[32m\"driver-K\"\u001b[39m,\n",
       "    \u001b[32m19.1\u001b[39m,\n",
       "    \u001b[32m\"san_francisco\"\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    \u001b[32m1695091554788L\u001b[39m,\n",
       "    \u001b[32m\"e96c4396-3fad-413a-a942-4cb36106d721\"\u001b[39m,\n",
       "    \u001b[32m\"rider-C\"\u001b[39m,\n",
       "    \u001b[32m\"driver-M\"\u001b[39m,\n",
       "    \u001b[32m27.7\u001b[39m,\n",
       "    \u001b[32m\"san_francisco\"\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    \u001b[32m1695046462179L\u001b[39m,\n",
       "    \u001b[32m\"9909a8b1-2d15-4d3d-8ec9-efc48c536a00\"\u001b[39m,\n",
       "    \u001b[32m\"rider-D\"\u001b[39m,\n",
       "    \u001b[32m\"driver-L\"\u001b[39m,\n",
       "    \u001b[32m33.9\u001b[39m,\n",
       "    \u001b[32m\"san_francisco\"\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    \u001b[32m1695516137016L\u001b[39m,\n",
       "    \u001b[32m\"e3cf430c-889d-4015-bc98-59bdce1e530c\"\u001b[39m,\n",
       "    \u001b[32m\"rider-F\"\u001b[39m,\n",
       "    \u001b[32m\"driver-P\"\u001b[39m,\n",
       "    \u001b[32m34.15\u001b[39m,\n",
       "    \u001b[32m\"sao_paulo\"\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    \u001b[32m1695115999911L\u001b[39m,\n",
       "    \u001b[32m\"c8abbe79-8d89-47ea-b4ce-4d224bae5bfa\"\u001b[39m,\n",
       "    \u001b[32m\"rider-J\"\u001b[39m,\n",
       "    \u001b[32m\"driver-T\"\u001b[39m,\n",
       "    \u001b[32m17.85\u001b[39m,\n",
       "...\n",
       "\u001b[36mtableName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"trips_table\"\u001b[39m\n",
       "\u001b[36mbasePath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"file:///tmp/hudi/trips_table\"\u001b[39m\n",
       "\u001b[36minserts\u001b[39m: \u001b[32mDataFrame\u001b[39m = [ts: bigint, uuid: string ... 4 more fields]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val columns = Seq(\"ts\",\"uuid\",\"rider\",\"driver\",\"fare\",\"city\")\n",
    "val data =\n",
    "  Seq((1695159649087L,\"334e26e9-8355-45cc-97c6-c31daf0df330\",\"rider-A\",\"driver-K\",19.10,\"san_francisco\"),\n",
    "    (1695091554788L,\"e96c4396-3fad-413a-a942-4cb36106d721\",\"rider-C\",\"driver-M\",27.70 ,\"san_francisco\"),\n",
    "    (1695046462179L,\"9909a8b1-2d15-4d3d-8ec9-efc48c536a00\",\"rider-D\",\"driver-L\",33.90 ,\"san_francisco\"),\n",
    "    (1695516137016L,\"e3cf430c-889d-4015-bc98-59bdce1e530c\",\"rider-F\",\"driver-P\",34.15,\"sao_paulo\"    ),\n",
    "    (1695115999911L,\"c8abbe79-8d89-47ea-b4ce-4d224bae5bfa\",\"rider-J\",\"driver-T\",17.85,\"chennai\"));\n",
    "\n",
    "val tableName = \"trips_table\"\n",
    "val basePath = \"file:///tmp/hudi/trips_table\"\n",
    "var inserts = spark.createDataFrame(data).toDF(columns:_*)\n",
    "inserts.write.format(\"hudi\").\n",
    "  option(\"hoodie.datasource.write.partitionpath.field\", \"city\").\n",
    "  option(\"hoodie.datasource.write.storage.type\", \"COPY_ON_WRITE\").\n",
    "  option(\"hoodie.table.name\", tableName).\n",
    "  mode(Overwrite).\n",
    "  save(basePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/\n",
      "└── trips_table\n",
      "    ├── .hoodie\n",
      "    │   ├── .aux\n",
      "    │   │   └── .bootstrap\n",
      "    │   │       ├── .fileids\n",
      "    │   │       └── .partitions\n",
      "    │   ├── .hoodie.properties.crc\n",
      "    │   ├── .schema\n",
      "    │   ├── .temp\n",
      "    │   ├── hoodie.properties\n",
      "    │   ├── metadata\n",
      "    │   │   ├── .hoodie\n",
      "    │   │   │   ├── .aux\n",
      "    │   │   │   │   └── .bootstrap\n",
      "    │   │   │   │       ├── .fileids\n",
      "    │   │   │   │       └── .partitions\n",
      "    │   │   │   ├── .hoodie.properties.crc\n",
      "    │   │   │   ├── .schema\n",
      "    │   │   │   ├── .temp\n",
      "    │   │   │   ├── hoodie.properties\n",
      "    │   │   │   └── timeline\n",
      "    │   │   │       ├── .00000000000000000.deltacommit.inflight.crc\n",
      "    │   │   │       ├── .00000000000000000.deltacommit.requested.crc\n",
      "    │   │   │       ├── .00000000000000000_20250302224308666.deltacommit.crc\n",
      "    │   │   │       ├── .20250302224307460.deltacommit.inflight.crc\n",
      "    │   │   │       ├── .20250302224307460.deltacommit.requested.crc\n",
      "    │   │   │       ├── .20250302224307460_20250302224310789.deltacommit.crc\n",
      "    │   │   │       ├── 00000000000000000.deltacommit.inflight\n",
      "    │   │   │       ├── 00000000000000000.deltacommit.requested\n",
      "    │   │   │       ├── 00000000000000000_20250302224308666.deltacommit\n",
      "    │   │   │       ├── 20250302224307460.deltacommit.inflight\n",
      "    │   │   │       ├── 20250302224307460.deltacommit.requested\n",
      "    │   │   │       ├── 20250302224307460_20250302224310789.deltacommit\n",
      "    │   │   │       └── history\n",
      "    │   │   └── files\n",
      "    │   │       ├── ..files-0000-0_00000000000000000.log.1_0-0-0.crc\n",
      "    │   │       ├── ..files-0000-0_20250302224307460.log.1_0-11-14.crc\n",
      "    │   │       ├── ..hoodie_partition_metadata.crc\n",
      "    │   │       ├── .files-0000-0_0-4-3_00000000000000000.hfile.crc\n",
      "    │   │       ├── .files-0000-0_00000000000000000.log.1_0-0-0\n",
      "    │   │       ├── .files-0000-0_20250302224307460.log.1_0-11-14\n",
      "    │   │       ├── .hoodie_partition_metadata\n",
      "    │   │       └── files-0000-0_0-4-3_00000000000000000.hfile\n",
      "    │   └── timeline\n",
      "    │       ├── .20250302224307460.commit.requested.crc\n",
      "    │       ├── .20250302224307460.inflight.crc\n",
      "    │       ├── .20250302224307460_20250302224310825.commit.crc\n",
      "    │       ├── 20250302224307460.commit.requested\n",
      "    │       ├── 20250302224307460.inflight\n",
      "    │       ├── 20250302224307460_20250302224310825.commit\n",
      "    │       └── history\n",
      "    ├── chennai\n",
      "    │   ├── ..hoodie_partition_metadata.crc\n",
      "    │   ├── .03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet.crc\n",
      "    │   ├── .hoodie_partition_metadata\n",
      "    │   └── 03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet\n",
      "    ├── san_francisco\n",
      "    │   ├── ..hoodie_partition_metadata.crc\n",
      "    │   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet.crc\n",
      "    │   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet.crc\n",
      "    │   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet.crc\n",
      "    │   ├── .hoodie_partition_metadata\n",
      "    │   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet\n",
      "    │   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet\n",
      "    │   └── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet\n",
      "    └── sao_paulo\n",
      "        ├── ..hoodie_partition_metadata.crc\n",
      "        ├── .c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet.crc\n",
      "        ├── .hoodie_partition_metadata\n",
      "        └── c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet\n",
      "\n",
      "24 directories, 46 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val result = \"tree -a /tmp/hudi/\".!!\n",
    "println(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+-------+--------+-------------+\n",
      "|                uuid| fare|           ts|  rider|  driver|         city|\n",
      "+--------------------+-----+-------------+-------+--------+-------------+\n",
      "|e96c4396-3fad-413...| 27.7|1695091554788|rider-C|driver-M|san_francisco|\n",
      "|9909a8b1-2d15-4d3...| 33.9|1695046462179|rider-D|driver-L|san_francisco|\n",
      "|e3cf430c-889d-401...|34.15|1695516137016|rider-F|driver-P|    sao_paulo|\n",
      "+--------------------+-----+-------------+-------+--------+-------------+\n",
      "\n",
      "+-------------------+--------------------+----------------------+-------+--------+-----+\n",
      "|_hoodie_commit_time|  _hoodie_record_key|_hoodie_partition_path|  rider|  driver| fare|\n",
      "+-------------------+--------------------+----------------------+-------+--------+-----+\n",
      "|  20250302224307460|20250302224307460...|         san_francisco|rider-C|driver-M| 27.7|\n",
      "|  20250302224307460|20250302224307460...|         san_francisco|rider-D|driver-L| 33.9|\n",
      "|  20250302224307460|20250302224307460...|         san_francisco|rider-A|driver-K| 19.1|\n",
      "|  20250302224307460|20250302224307460...|             sao_paulo|rider-F|driver-P|34.15|\n",
      "|  20250302224307460|20250302224307460...|               chennai|rider-J|driver-T|17.85|\n",
      "+-------------------+--------------------+----------------------+-------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtripsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 9 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tripsDF = spark.read.format(\"hudi\").load(basePath)\n",
    "tripsDF.createOrReplaceTempView(\"trips_table\")\n",
    "\n",
    "spark.sql(\"SELECT uuid, fare, ts, rider, driver, city FROM  trips_table WHERE fare > 20.0\").show()\n",
    "spark.sql(\"SELECT _hoodie_commit_time, _hoodie_record_key, _hoodie_partition_path, rider, driver, fare FROM  trips_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m\n",
       "\u001b[36mupdatesDf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 9 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Lets read data from target Hudi table, modify fare column for rider-D and update it. \n",
    "import spark.implicits._\n",
    "val updatesDf = spark.read.format(\"hudi\").load(basePath).filter($\"rider\" === \"rider-D\").withColumn(\"fare\", col(\"fare\") * 10)\n",
    "\n",
    "updatesDf.write.format(\"hudi\").\n",
    "  option(\"hoodie.datasource.write.operation\", \"upsert\").\n",
    "  option(\"hoodie.datasource.write.partitionpath.field\", \"city\").\n",
    "  option(\"hoodie.table.name\", tableName).\n",
    "  mode(Append).\n",
    "  save(basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/trips_table\n",
      "├── .hoodie\n",
      "│   ├── .aux\n",
      "│   │   └── .bootstrap\n",
      "│   │       ├── .fileids\n",
      "│   │       └── .partitions\n",
      "│   ├── .hoodie.properties.crc\n",
      "│   ├── .schema\n",
      "│   ├── .temp\n",
      "│   ├── hoodie.properties\n",
      "│   ├── metadata\n",
      "│   │   ├── .hoodie\n",
      "│   │   │   ├── .aux\n",
      "│   │   │   │   └── .bootstrap\n",
      "│   │   │   │       ├── .fileids\n",
      "│   │   │   │       └── .partitions\n",
      "│   │   │   ├── .hoodie.properties.crc\n",
      "│   │   │   ├── .schema\n",
      "│   │   │   ├── .temp\n",
      "│   │   │   ├── hoodie.properties\n",
      "│   │   │   └── timeline\n",
      "│   │   │       ├── .00000000000000000.deltacommit.inflight.crc\n",
      "│   │   │       ├── .00000000000000000.deltacommit.requested.crc\n",
      "│   │   │       ├── .00000000000000000_20250302224308666.deltacommit.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224307460_20250302224310789.deltacommit.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224319342_20250302224320197.deltacommit.crc\n",
      "│   │   │       ├── 00000000000000000.deltacommit.inflight\n",
      "│   │   │       ├── 00000000000000000.deltacommit.requested\n",
      "│   │   │       ├── 00000000000000000_20250302224308666.deltacommit\n",
      "│   │   │       ├── 20250302224307460.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224307460.deltacommit.requested\n",
      "│   │   │       ├── 20250302224307460_20250302224310789.deltacommit\n",
      "│   │   │       ├── 20250302224319342.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224319342.deltacommit.requested\n",
      "│   │   │       ├── 20250302224319342_20250302224320197.deltacommit\n",
      "│   │   │       └── history\n",
      "│   │   └── files\n",
      "│   │       ├── ..files-0000-0_00000000000000000.log.1_0-0-0.crc\n",
      "│   │       ├── ..files-0000-0_20250302224307460.log.1_0-11-14.crc\n",
      "│   │       ├── ..files-0000-0_20250302224319342.log.1_0-28-49.crc\n",
      "│   │       ├── ..hoodie_partition_metadata.crc\n",
      "│   │       ├── .files-0000-0_0-4-3_00000000000000000.hfile.crc\n",
      "│   │       ├── .files-0000-0_00000000000000000.log.1_0-0-0\n",
      "│   │       ├── .files-0000-0_20250302224307460.log.1_0-11-14\n",
      "│   │       ├── .files-0000-0_20250302224319342.log.1_0-28-49\n",
      "│   │       ├── .hoodie_partition_metadata\n",
      "│   │       └── files-0000-0_0-4-3_00000000000000000.hfile\n",
      "│   └── timeline\n",
      "│       ├── .20250302224307460.commit.requested.crc\n",
      "│       ├── .20250302224307460.inflight.crc\n",
      "│       ├── .20250302224307460_20250302224310825.commit.crc\n",
      "│       ├── .20250302224319342.commit.requested.crc\n",
      "│       ├── .20250302224319342.inflight.crc\n",
      "│       ├── .20250302224319342_20250302224320224.commit.crc\n",
      "│       ├── 20250302224307460.commit.requested\n",
      "│       ├── 20250302224307460.inflight\n",
      "│       ├── 20250302224307460_20250302224310825.commit\n",
      "│       ├── 20250302224319342.commit.requested\n",
      "│       ├── 20250302224319342.inflight\n",
      "│       ├── 20250302224319342_20250302224320224.commit\n",
      "│       └── history\n",
      "├── chennai\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   └── 03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet\n",
      "├── san_francisco\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet.crc\n",
      "│   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet.crc\n",
      "│   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet\n",
      "│   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet\n",
      "│   └── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet\n",
      "└── sao_paulo\n",
      "    ├── ..hoodie_partition_metadata.crc\n",
      "    ├── .c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet.crc\n",
      "    ├── .hoodie_partition_metadata\n",
      "    └── c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet\n",
      "\n",
      "23 directories, 62 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val result = \"tree -a /tmp/hudi/trips_table\".!!\n",
    "println(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-------+\n",
      "|_hoodie_commit_time| fare|  rider|\n",
      "+-------------------+-----+-------+\n",
      "|  20250302224307460| 27.7|rider-C|\n",
      "|  20250302224307460| 19.1|rider-A|\n",
      "|  20250302224319342|339.0|rider-D|\n",
      "|  20250302224307460|34.15|rider-F|\n",
      "|  20250302224307460|17.85|rider-J|\n",
      "+-------------------+-----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtripsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 9 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tripsDF = spark.read.format(\"hudi\").load(basePath)\n",
    "tripsDF.createOrReplaceTempView(\"trips_table\")\n",
    "spark.sql(s\"SELECT _hoodie_commit_time, fare, rider FROM trips_table;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|           ts|                uuid|  rider|  driver| fare|         city|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "|  20250302224329108|20250302224329108...|20250302224307460...|         san_francisco|70b25292-6a13-464...|1695091554788|e96c4396-3fad-413...|rider-C|driver-M|304.7|san_francisco|\n",
      "|  20250302224329108|20250302224329108...|20250302224307460...|         san_francisco|c1ce8a49-9626-449...|1695159649087|334e26e9-8355-45c...|rider-A|driver-K|210.1|san_francisco|\n",
      "|  20250302224319342|20250302224319342...|20250302224307460...|         san_francisco|1589be90-924e-4a6...|1695046462179|9909a8b1-2d15-4d3...|rider-D|driver-L|339.0|san_francisco|\n",
      "|  20250302224307460|20250302224307460...|20250302224307460...|             sao_paulo|c2e595be-4e97-47d...|1695516137016|e3cf430c-889d-401...|rider-F|driver-P|34.15|    sao_paulo|\n",
      "|  20250302224307460|20250302224307460...|20250302224307460...|               chennai|03526c02-175a-4ec...|1695115999911|c8abbe79-8d89-47e...|rider-J|driver-T|17.85|      chennai|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36madjustedFareDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 9 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val adjustedFareDF = spark.read.format(\"hudi\").\n",
    "  load(basePath).limit(2).\n",
    "  withColumn(\"fare\", col(\"fare\") * 10)\n",
    "\n",
    "adjustedFareDF.write.format(\"hudi\").\n",
    "  option(\"hoodie.datasource.write.payload.class\",\"com.payloads.CustomMergeIntoConnector\").\n",
    "  mode(Append).\n",
    "  save(basePath)\n",
    "// Notice Fare column has been updated but all other columns remain intact.\n",
    "spark.read.format(\"hudi\").load(basePath).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For rider-A, the fare previously was 19.1, now its 210.1.\n",
    "    * In the adjustedFareDF, the fare is 10*fare, so adjustedFare is 191.\n",
    "    * In the CustomMergeIntoConnector, the final fare is the original fare + adjustedFare, which is 19.1 + 191, thus it is 210.1.\n",
    "    * The same applies for rider-D.\n",
    "* If you notice, with 1 update and 1 merge upsert, now we have 6 parquet files for partition san_francisco.\n",
    "* The update generated 1 additional parquet file and the upsert added 2 extra files because we are modifying two parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/trips_table\n",
      "├── .hoodie\n",
      "│   ├── .aux\n",
      "│   │   └── .bootstrap\n",
      "│   │       ├── .fileids\n",
      "│   │       └── .partitions\n",
      "│   ├── .hoodie.properties.crc\n",
      "│   ├── .schema\n",
      "│   ├── .temp\n",
      "│   ├── hoodie.properties\n",
      "│   ├── metadata\n",
      "│   │   ├── .hoodie\n",
      "│   │   │   ├── .aux\n",
      "│   │   │   │   └── .bootstrap\n",
      "│   │   │   │       ├── .fileids\n",
      "│   │   │   │       └── .partitions\n",
      "│   │   │   ├── .hoodie.properties.crc\n",
      "│   │   │   ├── .schema\n",
      "│   │   │   ├── .temp\n",
      "│   │   │   ├── hoodie.properties\n",
      "│   │   │   └── timeline\n",
      "│   │   │       ├── .00000000000000000.deltacommit.inflight.crc\n",
      "│   │   │       ├── .00000000000000000.deltacommit.requested.crc\n",
      "│   │   │       ├── .00000000000000000_20250302224308666.deltacommit.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224307460_20250302224310789.deltacommit.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224319342_20250302224320197.deltacommit.crc\n",
      "│   │   │       ├── .20250302224329108.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224329108.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224329108_20250302224329869.deltacommit.crc\n",
      "│   │   │       ├── 00000000000000000.deltacommit.inflight\n",
      "│   │   │       ├── 00000000000000000.deltacommit.requested\n",
      "│   │   │       ├── 00000000000000000_20250302224308666.deltacommit\n",
      "│   │   │       ├── 20250302224307460.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224307460.deltacommit.requested\n",
      "│   │   │       ├── 20250302224307460_20250302224310789.deltacommit\n",
      "│   │   │       ├── 20250302224319342.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224319342.deltacommit.requested\n",
      "│   │   │       ├── 20250302224319342_20250302224320197.deltacommit\n",
      "│   │   │       ├── 20250302224329108.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224329108.deltacommit.requested\n",
      "│   │   │       ├── 20250302224329108_20250302224329869.deltacommit\n",
      "│   │   │       └── history\n",
      "│   │   └── files\n",
      "│   │       ├── ..files-0000-0_00000000000000000.log.1_0-0-0.crc\n",
      "│   │       ├── ..files-0000-0_20250302224307460.log.1_0-11-14.crc\n",
      "│   │       ├── ..files-0000-0_20250302224319342.log.1_0-28-49.crc\n",
      "│   │       ├── ..files-0000-0_20250302224329108.log.1_0-47-74.crc\n",
      "│   │       ├── ..hoodie_partition_metadata.crc\n",
      "│   │       ├── .files-0000-0_0-4-3_00000000000000000.hfile.crc\n",
      "│   │       ├── .files-0000-0_00000000000000000.log.1_0-0-0\n",
      "│   │       ├── .files-0000-0_20250302224307460.log.1_0-11-14\n",
      "│   │       ├── .files-0000-0_20250302224319342.log.1_0-28-49\n",
      "│   │       ├── .files-0000-0_20250302224329108.log.1_0-47-74\n",
      "│   │       ├── .hoodie_partition_metadata\n",
      "│   │       └── files-0000-0_0-4-3_00000000000000000.hfile\n",
      "│   └── timeline\n",
      "│       ├── .20250302224307460.commit.requested.crc\n",
      "│       ├── .20250302224307460.inflight.crc\n",
      "│       ├── .20250302224307460_20250302224310825.commit.crc\n",
      "│       ├── .20250302224319342.commit.requested.crc\n",
      "│       ├── .20250302224319342.inflight.crc\n",
      "│       ├── .20250302224319342_20250302224320224.commit.crc\n",
      "│       ├── .20250302224329108.commit.requested.crc\n",
      "│       ├── .20250302224329108.inflight.crc\n",
      "│       ├── .20250302224329108_20250302224329890.commit.crc\n",
      "│       ├── 20250302224307460.commit.requested\n",
      "│       ├── 20250302224307460.inflight\n",
      "│       ├── 20250302224307460_20250302224310825.commit\n",
      "│       ├── 20250302224319342.commit.requested\n",
      "│       ├── 20250302224319342.inflight\n",
      "│       ├── 20250302224319342_20250302224320224.commit\n",
      "│       ├── 20250302224329108.commit.requested\n",
      "│       ├── 20250302224329108.inflight\n",
      "│       ├── 20250302224329108_20250302224329890.commit\n",
      "│       └── history\n",
      "├── chennai\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   └── 03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet\n",
      "├── san_francisco\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet.crc\n",
      "│   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-40-68_20250302224329108.parquet.crc\n",
      "│   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet.crc\n",
      "│   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-40-67_20250302224329108.parquet.crc\n",
      "│   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet\n",
      "│   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-40-68_20250302224329108.parquet\n",
      "│   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet\n",
      "│   ├── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-40-67_20250302224329108.parquet\n",
      "│   └── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet\n",
      "└── sao_paulo\n",
      "    ├── ..hoodie_partition_metadata.crc\n",
      "    ├── .c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet.crc\n",
      "    ├── .hoodie_partition_metadata\n",
      "    └── c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet\n",
      "\n",
      "23 directories, 80 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val result = \"tree -a /tmp/hudi/trips_table\".!!\n",
    "println(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data (Partial Updates) if use sql and not CustomMergeIntoConnector.\n",
    "* Skipped for now as it only works if the table is created using Spark SQL and not Scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdeletesDF\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 9 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark-shell\n",
    "// Lets  delete rider: rider-D\n",
    "val deletesDF = spark.read.format(\"hudi\").load(basePath).filter($\"rider\" === \"rider-F\")\n",
    "\n",
    "deletesDF.write.format(\"hudi\").\n",
    "  option(\"hoodie.datasource.write.operation\", \"delete\").\n",
    "  option(\"hoodie.datasource.write.partitionpath.field\", \"city\").\n",
    "  option(\"hoodie.table.name\", tableName).\n",
    "  mode(Append).\n",
    "  save(basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|           ts|                uuid|  rider|  driver| fare|         city|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "|  20250302224329108|20250302224329108...|20250302224307460...|         san_francisco|70b25292-6a13-464...|1695091554788|e96c4396-3fad-413...|rider-C|driver-M|304.7|san_francisco|\n",
      "|  20250302224329108|20250302224329108...|20250302224307460...|         san_francisco|c1ce8a49-9626-449...|1695159649087|334e26e9-8355-45c...|rider-A|driver-K|210.1|san_francisco|\n",
      "|  20250302224319342|20250302224319342...|20250302224307460...|         san_francisco|1589be90-924e-4a6...|1695046462179|9909a8b1-2d15-4d3...|rider-D|driver-L|339.0|san_francisco|\n",
      "|  20250302224307460|20250302224307460...|20250302224307460...|               chennai|03526c02-175a-4ec...|1695115999911|c8abbe79-8d89-47e...|rider-J|driver-T|17.85|      chennai|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+-------------+--------------------+-------+--------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"hudi\").load(basePath).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that in the sao_paulo partition, there is one extra parquet file.\n",
    "* I believe this is the tombstone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/hudi/trips_table\n",
      "├── .hoodie\n",
      "│   ├── .aux\n",
      "│   │   └── .bootstrap\n",
      "│   │       ├── .fileids\n",
      "│   │       └── .partitions\n",
      "│   ├── .hoodie.properties.crc\n",
      "│   ├── .schema\n",
      "│   ├── .temp\n",
      "│   ├── hoodie.properties\n",
      "│   ├── metadata\n",
      "│   │   ├── .hoodie\n",
      "│   │   │   ├── .aux\n",
      "│   │   │   │   └── .bootstrap\n",
      "│   │   │   │       ├── .fileids\n",
      "│   │   │   │       └── .partitions\n",
      "│   │   │   ├── .hoodie.properties.crc\n",
      "│   │   │   ├── .schema\n",
      "│   │   │   ├── .temp\n",
      "│   │   │   ├── hoodie.properties\n",
      "│   │   │   └── timeline\n",
      "│   │   │       ├── .00000000000000000.deltacommit.inflight.crc\n",
      "│   │   │       ├── .00000000000000000.deltacommit.requested.crc\n",
      "│   │   │       ├── .00000000000000000_20250302224308666.deltacommit.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224307460.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224307460_20250302224310789.deltacommit.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224319342.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224319342_20250302224320197.deltacommit.crc\n",
      "│   │   │       ├── .20250302224329108.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224329108.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224329108_20250302224329869.deltacommit.crc\n",
      "│   │   │       ├── .20250302224336062.deltacommit.inflight.crc\n",
      "│   │   │       ├── .20250302224336062.deltacommit.requested.crc\n",
      "│   │   │       ├── .20250302224336062_20250302224336643.deltacommit.crc\n",
      "│   │   │       ├── 00000000000000000.deltacommit.inflight\n",
      "│   │   │       ├── 00000000000000000.deltacommit.requested\n",
      "│   │   │       ├── 00000000000000000_20250302224308666.deltacommit\n",
      "│   │   │       ├── 20250302224307460.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224307460.deltacommit.requested\n",
      "│   │   │       ├── 20250302224307460_20250302224310789.deltacommit\n",
      "│   │   │       ├── 20250302224319342.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224319342.deltacommit.requested\n",
      "│   │   │       ├── 20250302224319342_20250302224320197.deltacommit\n",
      "│   │   │       ├── 20250302224329108.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224329108.deltacommit.requested\n",
      "│   │   │       ├── 20250302224329108_20250302224329869.deltacommit\n",
      "│   │   │       ├── 20250302224336062.deltacommit.inflight\n",
      "│   │   │       ├── 20250302224336062.deltacommit.requested\n",
      "│   │   │       ├── 20250302224336062_20250302224336643.deltacommit\n",
      "│   │   │       └── history\n",
      "│   │   └── files\n",
      "│   │       ├── ..files-0000-0_00000000000000000.log.1_0-0-0.crc\n",
      "│   │       ├── ..files-0000-0_20250302224307460.log.1_0-11-14.crc\n",
      "│   │       ├── ..files-0000-0_20250302224319342.log.1_0-28-49.crc\n",
      "│   │       ├── ..files-0000-0_20250302224329108.log.1_0-47-74.crc\n",
      "│   │       ├── ..files-0000-0_20250302224336062.log.1_0-62-104.crc\n",
      "│   │       ├── ..hoodie_partition_metadata.crc\n",
      "│   │       ├── .files-0000-0_0-4-3_00000000000000000.hfile.crc\n",
      "│   │       ├── .files-0000-0_00000000000000000.log.1_0-0-0\n",
      "│   │       ├── .files-0000-0_20250302224307460.log.1_0-11-14\n",
      "│   │       ├── .files-0000-0_20250302224319342.log.1_0-28-49\n",
      "│   │       ├── .files-0000-0_20250302224329108.log.1_0-47-74\n",
      "│   │       ├── .files-0000-0_20250302224336062.log.1_0-62-104\n",
      "│   │       ├── .hoodie_partition_metadata\n",
      "│   │       └── files-0000-0_0-4-3_00000000000000000.hfile\n",
      "│   └── timeline\n",
      "│       ├── .20250302224307460.commit.requested.crc\n",
      "│       ├── .20250302224307460.inflight.crc\n",
      "│       ├── .20250302224307460_20250302224310825.commit.crc\n",
      "│       ├── .20250302224319342.commit.requested.crc\n",
      "│       ├── .20250302224319342.inflight.crc\n",
      "│       ├── .20250302224319342_20250302224320224.commit.crc\n",
      "│       ├── .20250302224329108.commit.requested.crc\n",
      "│       ├── .20250302224329108.inflight.crc\n",
      "│       ├── .20250302224329108_20250302224329890.commit.crc\n",
      "│       ├── .20250302224336062.commit.requested.crc\n",
      "│       ├── .20250302224336062.inflight.crc\n",
      "│       ├── .20250302224336062_20250302224336670.commit.crc\n",
      "│       ├── 20250302224307460.commit.requested\n",
      "│       ├── 20250302224307460.inflight\n",
      "│       ├── 20250302224307460_20250302224310825.commit\n",
      "│       ├── 20250302224319342.commit.requested\n",
      "│       ├── 20250302224319342.inflight\n",
      "│       ├── 20250302224319342_20250302224320224.commit\n",
      "│       ├── 20250302224329108.commit.requested\n",
      "│       ├── 20250302224329108.inflight\n",
      "│       ├── 20250302224329108_20250302224329890.commit\n",
      "│       ├── 20250302224336062.commit.requested\n",
      "│       ├── 20250302224336062.inflight\n",
      "│       ├── 20250302224336062_20250302224336670.commit\n",
      "│       └── history\n",
      "├── chennai\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   └── 03526c02-175a-4ecd-ad1e-367afa39f4c7-0_4-10-0_20250302224307460.parquet\n",
      "├── san_francisco\n",
      "│   ├── ..hoodie_partition_metadata.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet.crc\n",
      "│   ├── .1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet.crc\n",
      "│   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-40-68_20250302224329108.parquet.crc\n",
      "│   ├── .70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet.crc\n",
      "│   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-40-67_20250302224329108.parquet.crc\n",
      "│   ├── .c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet.crc\n",
      "│   ├── .hoodie_partition_metadata\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_0-22-44_20250302224319342.parquet\n",
      "│   ├── 1589be90-924e-4a63-bdb7-0bba51163eee-0_2-8-0_20250302224307460.parquet\n",
      "│   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-40-68_20250302224329108.parquet\n",
      "│   ├── 70b25292-6a13-464f-8371-b3116f101383-0_1-7-0_20250302224307460.parquet\n",
      "│   ├── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-40-67_20250302224329108.parquet\n",
      "│   └── c1ce8a49-9626-4490-9a1c-392ade77f827-0_0-6-0_20250302224307460.parquet\n",
      "└── sao_paulo\n",
      "    ├── ..hoodie_partition_metadata.crc\n",
      "    ├── .c2e595be-4e97-47dd-bc23-7f1e8a444523-0_0-56-99_20250302224336062.parquet.crc\n",
      "    ├── .c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet.crc\n",
      "    ├── .hoodie_partition_metadata\n",
      "    ├── c2e595be-4e97-47dd-bc23-7f1e8a444523-0_0-56-99_20250302224336062.parquet\n",
      "    └── c2e595be-4e97-47dd-bc23-7f1e8a444523-0_3-9-0_20250302224307460.parquet\n",
      "\n",
      "23 directories, 96 files\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">result</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: white\"><span class=\"ansi-white-fg\">[lazy]</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mString\u001b[39m = \u001b[37m[lazy]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val result = \"tree -a /tmp/hudi/trips_table\".!!\n",
    "println(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
